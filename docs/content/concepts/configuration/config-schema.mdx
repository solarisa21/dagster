---
title: Run Configuration | Dagster
description: Job run configuration allows providing parameters to jobs at the time they're executed.
---

# Run Configuration

Run configuration allows providing parameters to jobs at the time they're executed.

## Relevant APIs

| Name                                                 | Description                                              |
| ---------------------------------------------------- | -------------------------------------------------------- |
| <PyObject module="dagster" object="ConfigSchema"  /> | See details with code examples in the API documentation. |

## Overview

It's often useful to configure ops, assets, or resources at run time. For example, you might want to choose what dataset some op runs at the time the containing job is launched. In general, you should use Dagster's config system when you want to modulate a computation at runtime without needing to modify the job definition.

The objects that compose a job - assets, ops, and resources - are each individually configurable. When executing a job, you can supply "run configuration" that specifies the configuration for each of the objects in the job. When you execute a job with Dagster's Python API, you supply run configuration as a Python dictionary. When you execute a job from Dagit or the CLI, you can provide config in a YAML document.

A common use of configuration is for a [schedule](/concepts/partitions-schedules-sensors/schedules) or [sensor](/concepts/partitions-schedules-sensors/schedules) to provide configuration to the job run it is launching. For example, a daily schedule might provide the day it's running on to one of the ops as a config value, and that op might use that config value to decide what day's data to read.

Dagster includes a system for gradually-typed configuration schemas. These make it easy to catch configuration errors before job execution, as well as to learn what configuration is required to execute a job.

## Defining and Accessing Configuration for an Op, Asset, or Resource

Configurable parameters accepted by an op, asset, or resource are specified by providing a `config_schema` to the corresponding decorator. The structure of a `config_schema` is very flexible and [fully documented in the API Reference](/\_apidocs/config). However, most of the time you will want to provide a Python dictionary, with keys the names of parameters and values the types of those parameters.

During execution, the specified parameters are accessible within the body of the op/asset/resource under `context.op_config` (for ops/assets) or `context.resource_config` (for resources). It might seem confusing that asset config is accessed under `context.op_config` instead of `context.asset_config`. However, assets are wrappers for ops, so when we access asset config we are literally just accessing config for the underlying op.

Below we define a simple op and asset with identical `config_schemas` defining a single configurable parameter, `person_name`, as well as a resource with a configurable `url` parameter:

```python file=/concepts/configuration/configurable_op_asset_resource.py startafter=start endbefore=end
@op(config_schema={"person_name": str})
def op_using_config(context):
    return f'hello {context.op_config["person_name"]}'


@asset(config_schema={"person_name": str})
def asset_using_config(context):
    # Note how asset config is also accessed with context.op_config
    return f'hello {context.op_config["person_name"]}'


@resource(config_schema={"url": str})
def resource_using_config(context):
    return MyDatabaseConnection(context.resource_config["url"])
```

<Note>
  It is technically possible to access `context.op_config` inside ops (not
  assets) without defining a `config_schema`. However, this is not recommended
  and will likely be deprecated in the future.
</Note>

You can also build config into jobs, as described in [this section of the Jobs concept page](/concepts/ops-jobs-graphs/jobs#configuring-jobs).

## Specifying Runtime Configuration

If we want to execute `op_using_config` or materialize `asset_using_config`, we'll need to provide values for the parameters specified in `config_schema`. How we provide these values depends on the interface we are using.

### Python

From the Python API, we can use the `run_config` argument for <PyObject object="JobDefinition" method="execute_in_process"/> or <PyObject module="materialize"/>. This takes a dictionary where configuration values for ops/assets are specified under `ops.<op_or_asset_name>.config` (for resources under `resources.<resource_name>.config`):

```python file=/concepts/configuration/execute_with_config.py startafter=start_execute_with_config endbefore=end_execute_with_config dedent=4
@job
def example_job():
    op_using_config()

job_result = example_job.execute_in_process(
    run_config={"ops": {"op_using_config": {"config": {"person_name": "Alice"}}}}
)

asset_result = materialize(
    [asset_using_config],
    run_config={
        "ops": {"asset_using_config": {"config": {"person_name": "Alice"}}}
    },
)
```

### Dagit

From Dagit's [Launchpad](/concepts/dagit/dagit#launchpad), we supply config as YAML using the config editor. The editor has typeahead, schema validation, and schema documentation. You can also click the "Scaffold Missing Config" button to generate dummy values based on the config schema. Note that a modal containing the launchpad editor will pop up if we attempt to materialize an asset with a defined `config_schema`:

<Image
alt="Config in Dagit"
src="/images/concepts/config-dagit.png"
width={3808}
height={2414}
/>

### Command Line

When executing a job from Dagster's CLI with [dagster job execute](/\_apidocs/cli#dagster-job-execute), we can put config in a YAML file and pass the file path with the `--config` option:

```YAML file=/concepts/configuration/good.yaml
ops:
  op_using_config:
    config:
      person_name: Alice
```

```bash
dagster job execute --config my_config.yaml
```

## Validation

Dagster validates any provided run config against the corresponding config schemas. It will abort execution with a <PyObject object="DagsterInvalidConfigError"/> if validation fails. For example, both of the following will fail, because there is no `nonexistent_config_value` in the config schema:

```python file=/concepts/configuration/execute_with_config.py startafter=start_execute_with_bad_config endbefore=end_execute_with_bad_config dedent=4
@job
def example_job():
    op_using_config()

op_result = example_job.execute_in_process(
    run_config={
        "ops": {"op_using_config": {"config": {"nonexistent_config_value": 1}}}
    }
)

asset_result = materialize(
    [asset_using_config],
    run_config={
        "ops": {"asset_using_config": {"config": {"nonexistent_config_value": 1}}}
    },
)
```

## Examples

### Passing Configuration to Multiple Ops in a Job

If you want multiple ops to share values, You can use <PyObject module="dagster" object="make_values_resource" /> to pass the values via a resource and reference that resource from any op that needs it.

It defaults to <PyObject module="dagster" object="Any" /> type, meaning Dagster will accept any config value provided for the resource:

```python file=/concepts/configuration/make_values_resource_any.py
from dagster import job, make_values_resource, op


@op(required_resource_keys={"value"})
def needs_value(context):
    context.log.info(f"value: {context.resources.value}")


@op(required_resource_keys={"value"})
def also_needs_value(context):
    context.log.info(f"value: {context.resources.value}")


@job(resource_defs={"value": make_values_resource()})
def basic_job():
    needs_value()
    also_needs_value()


basic_result = basic_job.execute_in_process(
    run_config={"resources": {"value": {"config": "some_value"}}}
)
```

You can also specify the schema of the values like:

```python file=/concepts/configuration/make_values_resource_config_schema.py
from dagster import job, make_values_resource, op


@op(required_resource_keys={"values"})
def needs_value(context):
    context.log.info(f"my str: {context.resources.values['my_str']}")


@op(required_resource_keys={"values"})
def needs_different_value(context):
    context.log.info(f"my int: {context.resources.values['my_int']}")


@job(resource_defs={"values": make_values_resource(my_str=str, my_int=int)})
def different_values_job():
    needs_value()
    needs_different_value()


result = different_values_job.execute_in_process(
    run_config={"resources": {"values": {"config": {"my_str": "foo", "my_int": 1}}}}
)
```

And pass the values via a run config like so:

```YAML file=/concepts/configuration/make_values_resource_values.yaml
resources:
  values:
    config:
      my_str: foo
      my_int: 1
```

## See it in action

For more examples of jobs, check out the following in our [Hacker News example](https://github.com/dagster-io/dagster/tree/master/examples/hacker_news):

- [Config schema on a resource](https://github.com/dagster-io/dagster/blob/master/examples/hacker_news/hacker_news/resources/parquet_io_manager.py)
